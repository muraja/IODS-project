# Logistic Regression

```{r}
alc <- read_csv("C:/Users/SM/Documents/IODS-project/data/alc.csv")
colnames(alc)
```

Description of the data:

1.  The purpose of your analysis is to study the relationships between high/low alcohol consumption and some of the other variables in the data. To do this, choose 4 interesting variables in the data and for each of them, present your personal hypothesis about their relationships with alcohol consumption. **(0-1 point)**

    ```{r}
    g1 <- ggplot(data = alc, aes(x = alc_use))

    # define the plot as a bar plot and draw it
    g1 + geom_bar()

    # initialize a plot of 'high_use'
    g2 <- ggplot(data = alc, aes(x = high_use))

    # draw a bar plot of high_use by sex
    g2 + geom_bar()
    ```

2.  Numerically and graphically explore the distributions of your chosen variables and their relationships with alcohol consumption (use for example cross-tabulations, bar plots and box plots). Comment on your findings and compare the results of your exploration to your previously stated hypotheses. \*\*(0-5 points)

    ```{r}
    # access the tidyverse libraries tidyr, dplyr, ggplot2
    library(tidyr); library(dplyr); library(ggplot2)

    # glimpse at the alc data
    alc %>% glimpse()

    # use gather() to gather columns into key-value pairs and then glimpse() at the resulting data
    gather(alc) %>% glimpse

    # it may help to take a closer look by View() and browse the data
    gather(alc) %>% View

    # draw a bar plot of each variable
    gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free")

    # access the tidyverse libraries dplyr and ggplot2
    library(dplyr); library(ggplot2)

    # produce summary statistics by group
    alc %>% group_by(sex) %>% summarise(count = n())
    alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))


    # Work with the exercise in this chunk, step-by-step. Fix the R code!
    library(ggplot2)

    # initialize a plot of high_use and G3
    g1 <- ggplot(alc, aes(x = high_use, y = G3))

    # define the plot as a boxplot and draw it
    g1 + geom_boxplot() + ylab("grade")

    # initialize a plot of high_use and absences
    g2 <- ggplot(alc, aes(x = high_use, y = absences))

    # define the plot as a box plot and draw it
    g2 + geom_boxplot()
    ```

3.  Use logistic regression to statistically explore the relationship between your chosen variables and the binary high/low alcohol consumption variable as the target variable. Present and interpret a summary of the fitted model. Present and interpret the coefficients of the model as odds ratios and provide confidence intervals for them. Interpret the results and compare them to your previously stated hypothesis. **Hint**: If your model includes factor variables see for example the RHDS book or the first answer of [this stackexchange](http://stats.stackexchange.com/questions/60817/significance-of-categorical-predictor-in-logistic-regression) thread on how R treats and how you should interpret these variables in the model output (or use some other resource to study this). \*\*(0-5 points

    ```{r}
    # alc is available 
    alc
    # find the model with glm()
    m <- glm(high_use ~ failures + absences, data = alc, family = "binomial")

    # print out a summary of the model
    summary(m)

    # print out the coefficients of the model
    coef(m)
    ```

4.  Using the variables which, according to your logistic regression model, had a statistical relationship with high/low alcohol consumption, explore the predictive power of you model. Provide a 2x2 cross tabulation of predictions versus the actual values and optionally display a graphic visualizing both the actual values and the predictions. Compute the total proportion of inaccurately classified individuals (= the training error) and comment on all the results. Compare the performance of the model with performance achieved by some simple guessing strategy. **(0-3 points)**

```{r}
alc
# find the model with glm()
m <- glm(high_use ~ failures + absences + sex, data = alc, family = "binomial")

# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)


# fit the model
m <- glm(high_use ~ failures + absences + sex, data = alc, family = "binomial")

# predict() the probability of high_use
probabilities <- predict(m, type = "response")

library(dplyr)
# add the predicted probabilities to 'alc'
alc <- mutate(alc, probability = probabilities)

# use the probabilities to make a prediction of high_use
alc <- mutate(alc, prediction = high_use)

# see the last ten original classes, predicted probabilities, and class predictions
select(alc, failures, absences, sex, high_use, probability, prediction) %>% tail(10)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction)





# access dplyr and ggplot2
library(dplyr); library(ggplot2)

# initialize a plot of 'high_use' versus 'probability' in 'alc'
g <- ggplot(alc, aes(x = probability, y = high_use))

# define the geom as points and draw the plot
g + geom_point()
g + geom_point(aes(col = prediction))

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) 
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins



# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = 0)
  # the proportion of false predictions if none of the subjects actually had high use
loss_func(class = alc$high_use, prob = 1)
  # the proportion of false predictions if all subjects had high use
loss_func(class = alc$high_use, prob = alc$probability)
  # the proportion of false predictions in the population this prediction is based on!
```

5.  ***Bonus**: Perform 10-fold cross-validation on your model. Does your model have better test set performance (smaller prediction error using 10-fold cross-validation) compared to the model introduced in the Exercise Set (which had about 0.26 error). Could you find such a model?Â **(0-2 points to compensate any loss of points from the above exercises)***

```{r}

```

6.  ***Super-Bonus:** Perform cross-validation to compare the performance of different logistic regression models (= different sets of predictors). Start with a very high number of predictors and explore the changes in the training and testing errors as you move to models with less predictors. Draw a graph displaying the trends of both training and testing errors by the number of predictors in the model. **(0-4 points to compensate any loss of points from the above exercises)***
